  # 🛍️ Retail ETL Pipeline using PySpark on Google Colab

This project demonstrates a scalable ETL pipeline using **PySpark** in **Google Colab**, built to clean, enrich, and analyze retail sales data.

## 🚀 Features

- Data quality checks (nulls, invalid rows)
- Revenue calculations and enrichment
- Monthly sales trend analysis by product category
- Customer segmentation by age group and gender
- Top product categories per month
- Output written to multiple CSVs

## 🛠️ Tech Stack

- PySpark
- Google Colab
- Python (Pandas, shutil)
- ZIP download automation
- Optional integration with AWS S3 or Airflow

## 📁 Project Structure

retail-etl-pipeline/
├── retail_etl_colab.ipynb # Main Colab notebook
├── data/
│ └── retail_sales_dataset.csv # Input sample
├── output/
└── README.md

## 🧠 Skills Demonstrated

- Data Engineering & Transformation
- ETL design with PySpark
- Grouping, Aggregation, and Ranking
- Colab-based pipeline execution

## 🧪 Sample Visual Output

> ![Example Screenshot](./output_samples/summary_view.png)  ← *(Add your own!)*

---

## 📥 Get Started

1. Open the notebook in Colab
2. Upload your `retail_sales_dataset.csv`
3. Run step-by-step from extraction to ZIP download
4. Analyze or present results

---

## 📢 Author

**Abhinandhan Velagapudi**  
M.S. in Applied Data Science  
[LinkedIn Profile](https://www.linkedin.com/in/your-link)

---

## 📄 License

MIT License
