  # ğŸ›ï¸ Retail ETL Pipeline using PySpark on Google Colab

This project demonstrates a scalable ETL pipeline using **PySpark** in **Google Colab**, built to clean, enrich, and analyze retail sales data.

## ğŸš€ Features

- Data quality checks (nulls, invalid rows)
- Revenue calculations and enrichment
- Monthly sales trend analysis by product category
- Customer segmentation by age group and gender
- Top product categories per month
- Output written to multiple CSVs

## ğŸ› ï¸ Tech Stack

- PySpark
- Google Colab
- Python (Pandas, shutil)
- ZIP download automation
- Optional integration with AWS S3 or Airflow

## ğŸ“ Project Structure

retail-etl-pipeline/
â”œâ”€â”€ retail_etl_colab.ipynb # Main Colab notebook
â”œâ”€â”€ data/
â”‚ â””â”€â”€ retail_sales_dataset.csv # Input sample
â”œâ”€â”€ output/
â””â”€â”€ README.md

## ğŸ§  Skills Demonstrated

- Data Engineering & Transformation
- ETL design with PySpark
- Grouping, Aggregation, and Ranking
- Colab-based pipeline execution

## ğŸ§ª Sample Visual Output

> ![Example Screenshot](./output_samples/summary_view.png)  â† *(Add your own!)*

---

## ğŸ“¥ Get Started

1. Open the notebook in Colab
2. Upload your `retail_sales_dataset.csv`
3. Run step-by-step from extraction to ZIP download
4. Analyze or present results

---

## ğŸ“¢ Author

**Abhinandhan Velagapudi**  
M.S. in Applied Data Science  
[LinkedIn Profile](https://www.linkedin.com/in/your-link)

---

## ğŸ“„ License

MIT License
